{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "807eca1b",
            "metadata": {},
            "source": "# \u0414\u043e\u043c\u0430\u0448\u043d\u0435\u0435 \u0437\u0430\u0434\u0430\u043d\u0438\u0435 \u2116 2\n\u0421\u0435\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044f \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u0441 \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435\u043c \u0440\u043e\u0434\u0430 \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e YOLOv7."
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "4a2c3f06",
            "metadata": {
                "trusted": false
            },
            "outputs": [],
            "source": "import os\nimport shutil\nimport torch\nimport yaml\nfrom sklearn.model_selection import train_test_split\n\n%matplotlib inline"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "0ee91c5b",
            "metadata": {
                "trusted": false
            },
            "outputs": [],
            "source": "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
        },
        {
            "cell_type": "markdown",
            "id": "8256d694",
            "metadata": {},
            "source": "### \u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u043d\u0430\u0431\u043e\u0440\u0430 \u0434\u0430\u043d\u043d\u044b\u0445"
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "id": "f219c97e",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "import os  # noqa\nfrom pathlib import Path  # noqa\n\ndataset_path = Path(\"../../data/segmented\")"
        },
        {
            "cell_type": "markdown",
            "id": "dbd112bc",
            "metadata": {},
            "source": "\u0420\u0430\u0437\u043e\u0431\u044c\u0451\u043c \u0434\u0430\u0442\u0430\u0441\u0435\u0442 \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u0443\u044e \u0438 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0443\u044e \u0432\u044b\u0431\u043e\u0440\u043a\u0438"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "8e6b5353",
            "metadata": {
                "trusted": false
            },
            "outputs": [],
            "source": "test_size = 0.2  # \u0440\u0430\u0437\u043c\u0435\u0440 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0438\nvalid_size = 0.1  # \u0440\u0430\u0437\u043c\u0435\u0440 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0438"
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "id": "2129d3aa",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "image_files = [f for f in os.listdir(dataset_path) if f.endswith(\".jpg\")]\nannotation_files = [f for f in os.listdir(dataset_path) if f.endswith(\".txt\")]\n\nimage_files_with_annotations = [\n    f for f in image_files if f.replace(\".jpg\", \".txt\") in annotation_files\n]\n\ntrain_files, test_files = train_test_split(\n    image_files_with_annotations, test_size=test_size, random_state=42\n)\ntrain_files, valid_files = train_test_split(\n    train_files,\n    test_size=len(image_files_with_annotations) * valid_size / len(train_files),\n    random_state=42,\n)\n\n\ndef copy_files(files, source_path, dest_path):\n    for file in files:\n        shutil.copy(os.path.join(source_path, file), os.path.join(dest_path, \"images\"))\n        shutil.copy(\n            os.path.join(source_path, file.replace(\".jpg\", \".txt\")),\n            os.path.join(dest_path, \"labels\"),\n        )\n\n\nfor folder in [\"train\", \"valid\", \"test\"]:\n    os.makedirs(os.path.join(dataset_path, folder, \"images\"), exist_ok=True)\n    os.makedirs(os.path.join(dataset_path, folder, \"labels\"), exist_ok=True)\n\ncopy_files(train_files, dataset_path, os.path.join(dataset_path, \"train\"))\ncopy_files(valid_files, dataset_path, os.path.join(dataset_path, \"valid\"))\ncopy_files(test_files, dataset_path, os.path.join(dataset_path, \"test\"))\n\nfor file in os.listdir(dataset_path):\n    if not file.endswith(\".names\") and os.path.isfile(os.path.join(dataset_path, file)):\n        os.remove(os.path.join(dataset_path, file))"
        },
        {
            "cell_type": "markdown",
            "id": "aaced078",
            "metadata": {},
            "source": "\u0414\u043e\u0431\u0430\u0432\u0438\u043c \u043a\u043e\u043d\u0444\u0438\u0433 \u043a YOLO"
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "id": "a64803f2",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "train_path = f'{dataset_path}/train/images'\nval_path = f'{dataset_path}/valid/images'\ntest_path = f'{dataset_path}/test/images'\n\nnames_file = os.path.join(dataset_path, 'obj.names')\nwith open(names_file, 'r') as file:\n    class_names = [line.strip() for line in file.readlines()]\n\nnum_classes = len(class_names)\n\ndata = {\n    'train': train_path,\n    'val': val_path,\n    'test': test_path,\n    'nc': num_classes,\n    'names': class_names\n}\n\noutput_file = os.path.join(dataset_path, 'data.yaml')\nwith open(output_file, 'w') as file:\n    documents = yaml.dump(data, file)\n\nos.remove(os.path.join(dataset_path, 'obj.names'))"
        },
        {
            "cell_type": "markdown",
            "id": "fff49f93",
            "metadata": {},
            "source": "## \u0417\u0430\u043f\u0443\u0441\u043a \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f\n### \u0410\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u0430 \u0441\u0435\u0442\u0438"
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "0b1717bc",
            "metadata": {
                "trusted": false
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "/home/ds13/Projects/--educational/Bmstu__/t5-2-/Neuroscience__/t5-2-Neuroscience__Homework2/src/yolo_v7_gender_segmentation/yolov7\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/home/ds13/Projects/--educational/Bmstu__/t5-2-/Neuroscience__/t5-2-Neuroscience__Homework2/.pixi/envs/dev-ju-nvim/lib/python3.12/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
                }
            ],
            "source": "%cd yolov7"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "21dfae41",
            "metadata": {
                "trusted": false
            },
            "outputs": [],
            "source": "weights = torch.load('yolov7.pt', map_location=torch.device('cpu'))"
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "3f9f2cf8",
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "{'model': Model(\n  (model): Sequential(\n    (0): Conv(\n      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (1): Conv(\n      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (2): Conv(\n      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (3): Conv(\n      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (4): Conv(\n      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (5): Conv(\n      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (6): Conv(\n      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (7): Conv(\n      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (8): Conv(\n      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (9): Conv(\n      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (10): Concat()\n    (11): Conv(\n      (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (12): MP(\n      (m): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    )\n    (13): Conv(\n      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (14): Conv(\n      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (15): Conv(\n      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (16): Concat()\n    (17): Conv(\n      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (18): Conv(\n      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (19): Conv(\n      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (20): Conv(\n      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (21): Conv(\n      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (22): Conv(\n      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (23): Concat()\n    (24): Conv(\n      (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (25): MP(\n      (m): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    )\n    (26): Conv(\n      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (27): Conv(\n      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (28): Conv(\n      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (29): Concat()\n    (30): Conv(\n      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (31): Conv(\n      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (32): Conv(\n      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (33): Conv(\n      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (34): Conv(\n      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (35): Conv(\n      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (36): Concat()\n    (37): Conv(\n      (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(1024, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (38): MP(\n      (m): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    )\n    (39): Conv(\n      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (40): Conv(\n      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (41): Conv(\n      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (42): Concat()\n    (43): Conv(\n      (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (44): Conv(\n      (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (45): Conv(\n      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (46): Conv(\n      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (47): Conv(\n      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (48): Conv(\n      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (49): Concat()\n    (50): Conv(\n      (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(1024, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (51): SPPCSPC(\n      (cv1): Conv(\n        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU()\n      )\n      (cv2): Conv(\n        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU()\n      )\n      (cv3): Conv(\n        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU()\n      )\n      (cv4): Conv(\n        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU()\n      )\n      (m): ModuleList(\n        (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n        (1): MaxPool2d(kernel_size=9, stride=1, padding=4, dilation=1, ceil_mode=False)\n        (2): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)\n      )\n      (cv5): Conv(\n        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU()\n      )\n      (cv6): Conv(\n        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU()\n      )\n      (cv7): Conv(\n        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU()\n      )\n    )\n    (52): Conv(\n      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (53): Upsample(scale_factor=2.0, mode='nearest')\n    (54): Conv(\n      (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (55): Concat()\n    (56): Conv(\n      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (57): Conv(\n      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (58): Conv(\n      (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (59): Conv(\n      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (60): Conv(\n      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (61): Conv(\n      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (62): Concat()\n    (63): Conv(\n      (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (64): Conv(\n      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (65): Upsample(scale_factor=2.0, mode='nearest')\n    (66): Conv(\n      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (67): Concat()\n    (68): Conv(\n      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (69): Conv(\n      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (70): Conv(\n      (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (71): Conv(\n      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (72): Conv(\n      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (73): Conv(\n      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (74): Concat()\n    (75): Conv(\n      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (76): MP(\n      (m): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    )\n    (77): Conv(\n      (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (78): Conv(\n      (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (79): Conv(\n      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (80): Concat()\n    (81): Conv(\n      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (82): Conv(\n      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (83): Conv(\n      (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (84): Conv(\n      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (85): Conv(\n      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (86): Conv(\n      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (87): Concat()\n    (88): Conv(\n      (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (89): MP(\n      (m): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    )\n    (90): Conv(\n      (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (91): Conv(\n      (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (92): Conv(\n      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (93): Concat()\n    (94): Conv(\n      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (95): Conv(\n      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (96): Conv(\n      (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (97): Conv(\n      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (98): Conv(\n      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (99): Conv(\n      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (100): Concat()\n    (101): Conv(\n      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU()\n    )\n    (102): RepConv(\n      (act): SiLU()\n      (rbr_dense): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      )\n      (rbr_1x1): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      )\n    )\n    (103): RepConv(\n      (act): SiLU()\n      (rbr_dense): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      )\n      (rbr_1x1): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      )\n    )\n    (104): RepConv(\n      (act): SiLU()\n      (rbr_dense): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(1024, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      )\n      (rbr_1x1): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(1024, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      )\n    )\n    (105): Detect(\n      (m): ModuleList(\n        (0): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))\n        (1): Conv2d(512, 255, kernel_size=(1, 1), stride=(1, 1))\n        (2): Conv2d(1024, 255, kernel_size=(1, 1), stride=(1, 1))\n      )\n    )\n  )\n), 'optimizer': None, 'training_results': None, 'epoch': -1}\n"
                }
            ],
            "source": "print(weights)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### \u041d\u0430\u0447\u0430\u043b\u043e\n\n\u0427\u0442\u043e\u0431\u044b \u043f\u043e\u043b\u0443\u0447\u0438\u0442\u044c \u043f\u043e\u043b\u043d\u044b\u0439 \u0441\u043f\u0438\u0441\u043e\u043a \u0430\u0440\u0433\u0443\u043c\u0435\u043d\u0442\u043e\u0432 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f, \u043f\u0435\u0440\u0435\u0439\u0434\u0438\u0442\u0435 \u043f\u043e [\u0441\u0441\u044b\u043b\u043a\u0435](https://github.com/WongKinYiu/yolov7/blob/main/train.py)\n\n\u041d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0432\u0430\u0436\u043d\u044b\u0445 \u0430\u0440\u0433\u0443\u043c\u0435\u043d\u0442\u043e\u0432, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0441\u043b\u0435\u0434\u0443\u0435\u0442 \u0437\u043d\u0430\u0442\u044c\n\nconfiguration: \u0432 \u043e\u0441\u043d\u043e\u0432\u043d\u043e\u0439 \u043f\u0430\u043f\u043a\u0435 yolov7 \u043f\u0435\u0440\u0435\u0439\u0434\u0438\u0442\u0435 \u0432 \u043f\u0430\u043f\u043a\u0443 cfg/training \u0438 \u0432\u044b\u0431\u0435\u0440\u0438\u0442\u0435 \u043f\u0443\u0442\u044c \u043a \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0442\u0432\u0443\u044e\u0449\u0435\u043c\u0443 \u0444\u0430\u0439\u043b\u0443 \u043a\u043e\u043d\u0444\u0438\u0433\u0443\u0440\u0430\u0446\u0438\u0438. \u0423\u043a\u0430\u0436\u0438\u0442\u0435 \u043e\u0442\u043d\u043e\u0441\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0439 \u043f\u0443\u0442\u044c \u043a \u0444\u0430\u0439\u043b\u0443 \u0432 \u0430\u0440\u0433\u0443\u043c\u0435\u043d\u0442\u0435 --cfg.\ndata \u043f\u0443\u0442\u044c \u043a \u043f\u0430\u043f\u043a\u0435 \u0441 \u0434\u0430\u043d\u043d\u044b\u043c\u0438, \u043e\u043d\u0430 \u0431\u0443\u0434\u0435\u0442 \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u0430\u043d\u0430 \u0430\u0432\u0442\u043e\u043c\u0430\u0442\u0438\u0447\u0435\u0441\u043a\u0438\nweights \u043f\u0443\u0442\u044c \u043a \u043f\u0440\u0435\u0434\u0432\u0430\u0440\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u043e\u0431\u0443\u0447\u0435\u043d\u043d\u044b\u043c \u0432\u0435\u0441\u0430\u043c, \u0437\u0430\u0434\u0430\u043d\u043d\u044b\u0439 \u0430\u0440\u0433\u0443\u043c\u0435\u043d\u0442\u043e\u043c --weights"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "!python train.py --batch 16 --cfg cfg/training/yolov7.yaml --epochs 55 --data {dataset_path}/data.yaml --weights 'yolov7.pt'"
        },
        {
            "cell_type": "markdown",
            "id": "dc2bb763",
            "metadata": {},
            "source": "### \u0427\u0442\u0435\u043d\u0438\u0435 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u043e\u0439 \u0438 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0438"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d5bfd060",
            "metadata": {
                "trusted": false
            },
            "outputs": [],
            "source": "def stem_extensions(filename: Path):\n    extensions = \"\".join(filename.suffixes)\n\n    return str(filename).removesuffix(extensions)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "377b5566",
            "metadata": {
                "trusted": false
            },
            "outputs": [],
            "source": "dataset_path = Path(stem_extensions(file_path))\n\nwith open(dataset_path / \"train\", \"rb\") as f:\n    data_train = pickle.load(f, encoding=\"latin1\")\nwith open(dataset_path / \"test\", \"rb\") as f:\n    data_test = pickle.load(f, encoding=\"latin1\")\n\n# \u041a\u043b\u0430\u0441\u0441\u044b \u043f\u043e \u0432\u0430\u0440\u0438\u0430\u043d\u0442\u0443.\nCLASSES = [17, 70, 35]\n\ntrain_X_raw = data_train[\"data\"].reshape(-1, 3, 32, 32)\ntrain_X_raw = np.transpose(train_X_raw, [0, 2, 3, 1])  # NCHW -> NHWC\ntrain_y_raw = np.array(data_train[\"fine_labels\"])\nmask = np.isin(train_y_raw, CLASSES)\ntrain_X = train_X_raw[mask].copy()\ntrain_y = train_y_raw[mask].copy()\ntrain_y = np.unique(train_y, return_inverse=1)[1]\ndel data_train\n\ntest_X = data_test[\"data\"].reshape(-1, 3, 32, 32)\ntest_X = np.transpose(test_X, [0, 2, 3, 1])\ntest_y = np.array(data_test[\"fine_labels\"])\nmask = np.isin(test_y, CLASSES)\ntest_X = test_X[mask].copy()\ntest_y = test_y[mask].copy()\ntest_y = np.unique(test_y, return_inverse=1)[1]\ndel data_test\n\n# print(train_y_raw.tolist())"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b94450f8",
            "metadata": {
                "trusted": false
            },
            "outputs": [],
            "source": "def createImage(data: ArrayLike):\n    return Image.fromarray(data).resize((256, 256))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "03721df3",
            "metadata": {
                "trusted": false
            },
            "outputs": [],
            "source": "# Source: https://stackoverflow.com/a/47334314\ndef grid_display(list_of_images, list_of_titles=[], no_of_columns=2, figsize=(10, 10)):\n    fig = plt.figure(figsize=figsize)\n    column = 0\n    for i in range(len(list_of_images)):\n        column += 1\n        #  check for end of column and create a new figure\n        if column == no_of_columns + 1:\n            fig = plt.figure(figsize=figsize)\n            column = 1\n        fig.add_subplot(1, no_of_columns, column)\n        plt.imshow(list_of_images[i])\n        plt.axis(\"off\")\n        if len(list_of_titles) >= len(list_of_images):\n            plt.title(list_of_titles[i])"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1a8dc000",
            "metadata": {
                "trusted": false
            },
            "outputs": [],
            "source": "# \u041f\u043e 3 \u044d\u043a\u0437\u0435\u043c\u043f\u043b\u044f\u0440\u0430 \u043a\u043b\u0430\u0441\u0441\u0430 \u0438\u0437 \u0432\u044b\u0431\u043e\u0440\u043a\u0438.\nnumber_of_images_per_class_to_show = 3\n\nfor class_id in CLASSES:\n    print(f\"{class_id = }:\")\n    i = number_of_images_per_class_to_show\n    image_index_for_class = -1\n    class_images = []\n    image_indices = []\n\n    while i > 0:\n        image_index_for_class = train_y_raw.tolist().index(\n            class_id, image_index_for_class + 1\n        )\n        image_indices.append(image_index_for_class)\n        class_images.append(createImage(train_X_raw[image_index_for_class]))\n        i -= 1\n    grid_display(class_images, image_indices, number_of_images_per_class_to_show)\n    plt.show()"
        },
        {
            "cell_type": "markdown",
            "id": "ccbf78ce",
            "metadata": {},
            "source": "### \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 Cifar Dataset \u0441 \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0435\u0439"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4efa02e9",
            "metadata": {
                "trusted": false
            },
            "outputs": [],
            "source": "from torch import Tensor  # noqa\nfrom torch.utils.data import Dataset  # noqa\n\n\n# New:\nclass CifarDataset(Dataset):\n    def __init__(self, X: Tensor, y: Tensor, transform=None, p=0.0):\n        assert X.size(0) == y.size(0)\n        super(Dataset, self).__init__()\n        self.X = X\n        self.y = y\n        self.transform = transform\n        self.prob = p\n\n    def __len__(self):\n        return self.y.size(0)\n\n    def __getitem__(self, index):\n        X = self.X[index]\n        if self.transform and np.random.random() < self.prob:\n            X = self.transform(X.permute(2, 0, 1) / 255).permute(1, 2, 0) * 255\n\n        y = self.y[index]\n\n        return X, y"
        },
        {
            "cell_type": "markdown",
            "id": "9f627657",
            "metadata": {},
            "source": "\u041f\u043e\u043f\u0440\u043e\u0431\u0443\u0435\u043c \u043f\u0440\u0438\u043c\u0435\u043d\u0438\u0442\u044c \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044e \u043a \u043e\u0434\u043d\u043e\u0439 \u0438\u0437 \u043a\u0430\u0440\u0442\u0438\u043d\u043e\u043a."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "519243eb",
            "metadata": {
                "trusted": false
            },
            "outputs": [],
            "source": "import torchvision.transforms as T  # noqa\n\ntransform = T.Compose(\n    [\n        T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.2, hue=0.0),\n        # shear - \u0441\u0434\u0432\u0438\u0433.\n        T.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.8, 1.2), shear=15),\n    ]\n)\n\nImage.fromarray(\n    (CifarDataset(Tensor(train_X), Tensor(train_y), transform=transform, p=1)[10])[0]\n    .numpy()\n    .astype(np.uint8)\n).resize((256, 256))"
        },
        {
            "cell_type": "markdown",
            "id": "4244d916",
            "metadata": {},
            "source": "### \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 Pytorch DataLoader'a"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b2aa0125",
            "metadata": {
                "trusted": false
            },
            "outputs": [],
            "source": "def create_dataloader(batch_size=128):\n    dataloader: dict[str, DataLoader] = {}\n    for (X, y), part in zip([(train_X, train_y), (test_X, test_y)], [\"train\", \"test\"]):\n        tensor_x = torch.Tensor(X)\n        tensor_y = (\n            F.one_hot(torch.Tensor(y).to(torch.int64), num_classes=len(CLASSES)) / 1.0\n        )\n        # New: Using CifarDataset.\n        dataset = CifarDataset(\n            tensor_x, tensor_y, transform=transform if part == \"train\" else None, p=0.5\n        )  # \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043e\u0431\u044a\u0435\u043a\u0442\u0430 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0430\n        dataloader[part] = DataLoader(\n            dataset,\n            batch_size=batch_size,\n            shuffle=True,\n            # New: prefetch_factor, num_workers and persistent_workers params.\n            # prefetch_factor=8 if part == \"train\" else 2,\n            # num_workers=2,\n            # persistent_workers=True,\n        )  # \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u044d\u043a\u0437\u0435\u043c\u043f\u043b\u044f\u0440\u0430 \u043a\u043b\u0430\u0441\u0441\u0430 DataLoader\n\n    return dataloader"
        },
        {
            "cell_type": "markdown",
            "id": "7c165256",
            "metadata": {},
            "source": "### \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 Pytorch \u043c\u043e\u0434\u0435\u043b\u0438 \u0441\u0432\u0451\u0440\u0442\u043e\u0447\u043d\u043e\u0439 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u043e\u0439 \u0441\u0435\u0442\u0438"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4d3902b0",
            "metadata": {
                "trusted": false
            },
            "outputs": [],
            "source": "HIDDEN_SIZE = 64\n\n\nclass Normalize(nn.Module):\n    def __init__(self, mean, std):\n        super(Normalize, self).__init__()\n        self.mean = torch.tensor(mean).to(device)\n        self.std = torch.tensor(std).to(device)\n\n    def forward(self, input):\n        x = input / 255.0\n        x = x - self.mean\n        x = x / self.std\n        return x.permute(0, 3, 1, 2)  # nhwc -> nm\n\n\nclass GlobalMaxPool2d(nn.Module):\n    def __init__(self):\n        super(GlobalMaxPool2d, self).__init__()\n\n    def forward(self, input):\n        out = F.adaptive_max_pool2d(input, output_size=1)\n        return out.flatten(start_dim=1)\n\n\nclass Cifar100_CNN(nn.Module):\n    def __init__(self, hidden_size=HIDDEN_SIZE, classes=100):\n        super(Cifar100_CNN, self).__init__()\n        # https://blog.jovian.ai/image-classification-of-cifar100-dataset-using-pytorch-8b7145242df1\n        self.seq = nn.Sequential(\n            Normalize([0.5074, 0.4867, 0.4411], [0.2011, 0.1987, 0.2025]),\n            nn.Conv2d(3, hidden_size, 5, stride=4, padding=2),\n            nn.ReLU(),\n            # New\n            nn.Dropout2d(p=0.2),\n            nn.Conv2d(hidden_size, hidden_size * 2, 3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.AvgPool2d(4),  # nn.MaxPool2d(4),\n            # New\n            nn.Dropout2d(p=0.3),\n            nn.Flatten(),\n            nn.Linear(hidden_size * 8, classes),\n        )\n\n    def forward(self, input):\n        return self.seq(input)\n\n\nmodel = Cifar100_CNN(hidden_size=HIDDEN_SIZE, classes=len(CLASSES))\nmodel.to(device)\nprint(model(torch.rand(1, 32, 32, 3).to(device)))\nsummary(model, input_size=(32, 32, 3))\nweights = list(model.parameters())[0].detach().numpy()\nweights.shape"
        },
        {
            "cell_type": "markdown",
            "id": "b74975e5",
            "metadata": {},
            "source": "### \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043b\u043e\u0433\u043e\u0432 \u0434\u043b\u044f Tensorboard"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1cfd2c45",
            "metadata": {
                "trusted": false
            },
            "outputs": [],
            "source": "import time  # noqa\n\nfrom torch.utils.tensorboard import SummaryWriter  # noqa\n\n%load_ext tensorboard\n\ncurrent_time = str(int(time.time()))\n\nrun_path = Path(\"runs/tensorboard\")\n\ntrain_run_path = run_path / \"train\" / current_time\ntest_run_path = run_path / \"test\" / current_time\n\ntrain_summary_writer = SummaryWriter(log_dir=train_run_path)\ntest_summary_writer = SummaryWriter(log_dir=test_run_path)"
        },
        {
            "cell_type": "markdown",
            "id": "3a254a59",
            "metadata": {},
            "source": "### \u041e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u043e \u044d\u043f\u043e\u0445\u0430\u043c"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c2392bff",
            "metadata": {
                "trusted": false
            },
            "outputs": [],
            "source": "REDRAW_EVERY = 20\nEPOCHS = 250\n\n\ndef train(\n    model: nn.Module,\n    criterion: nn.CrossEntropyLoss,\n    optimizer: optim.Optimizer,\n    dataloader: dict[str, DataLoader],\n    scheduler: optim.lr_scheduler.LRScheduler,\n    epochs=EPOCHS,\n):\n    steps_per_epoch = len(dataloader[\"train\"])\n    steps_per_epoch_val = len(dataloader[\"test\"])\n\n    pbar = tqdm(total=epochs * steps_per_epoch)\n    losses = []\n    losses_val = []\n    passed = 0\n    # \u0414\u043b\u044f \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u044f \u0447\u0435\u043a\u043f\u043e\u0438\u043d\u0442\u0430\n    best_acc = 0\n    checkpoint_path = Path(\"cifar_cnn_augmented.pth\")\n\n    for epoch in range(epochs):  # \u043f\u0440\u043e\u0445\u043e\u0434 \u043f\u043e \u043d\u0430\u0431\u043e\u0440\u0443 \u0434\u0430\u043d\u043d\u044b\u0445 \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0440\u0430\u0437\n        tmp = []\n        model.train()\n        for i, batch in enumerate(dataloader[\"train\"], 0):\n            # \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u0438\u0435 \u043e\u0434\u043d\u043e\u0433\u043e \u043c\u0438\u043d\u0438\u0431\u0430\u0442\u0447\u0430; batch \u044d\u0442\u043e \u0434\u0432\u0443\u044d\u043b\u0435\u043c\u0435\u043d\u0442\u043d\u044b\u0439 \u0441\u043f\u0438\u0441\u043e\u043a \u0438\u0437 [inputs, labels]\n            inputs, labels = batch\n\n            # \u043e\u0447\u0438\u0449\u0435\u043d\u0438\u0435 \u043f\u0440\u043e\u0448\u043b\u044b\u0445 \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u043e\u0432 \u0441 \u043f\u0440\u043e\u0448\u043b\u043e\u0439 \u0438\u0442\u0435\u0440\u0430\u0446\u0438\u0438\n            optimizer.zero_grad()\n\n            # \u043f\u0440\u044f\u043c\u043e\u0439 + \u043e\u0431\u0440\u0430\u0442\u043d\u044b\u0439 \u043f\u0440\u043e\u0445\u043e\u0434\u044b + \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0446\u0438\u044f\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            # loss = F.cross_entropy(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            # \u0434\u043b\u044f \u043f\u043e\u0434\u0441\u0447\u0451\u0442\u0430 \u0441\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u043a\n            accuracy = (\n                labels.detach().argmax(dim=-1) == outputs.detach().argmax(dim=-1)\n            ).to(torch.float32).mean().cpu() * 100\n            tmp.append((loss.item(), accuracy.item()))\n            pbar.update(1)\n\n            # New: \u0417\u0430\u043f\u0438\u0441\u044c \u0432 tensorboard.\n            with train_summary_writer as writer:\n                writer.add_scalar(\"loss\", tmp[-1][0], global_step=pbar.n)\n                writer.add_scalar(\"accuracy\", tmp[-1][1], global_step=pbar.n)\n\n        losses.append(\n            (\n                np.mean(tmp, axis=0),\n                np.percentile(tmp, 25, axis=0),\n                np.percentile(tmp, 75, axis=0),\n            )\n        )\n        # New: \u0418\u043d\u0442\u0435\u0433\u0440\u0430\u0446\u0438\u044f \u0441\u043e scheduler.\n        scheduler.step()  # \u041e\u0431\u043d\u043e\u0432\u043b\u044f\u0435\u043c learning_rate \u043a\u0430\u0436\u0434\u0443\u044e \u044d\u043f\u043e\u0445\u0443.\n\n        tmp = []\n        model.eval()\n        with torch.no_grad():  # \u043e\u0442\u043a\u043b\u044e\u0447\u0435\u043d\u0438\u0435 \u0430\u0432\u0442\u043e\u043c\u0430\u0442\u0438\u0447\u0435\u0441\u043a\u043e\u0433\u043e \u0434\u0438\u0444\u0444\u0435\u0440\u0435\u043d\u0446\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f\n            for i, data in enumerate(dataloader[\"test\"], 0):\n                inputs, labels = data\n                # \u043d\u0430 GPU\n                # inputs, labels = inputs.to(device), labels.to(device)\n\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                accuracy = (labels.argmax(dim=-1) == outputs.argmax(dim=-1)).to(\n                    torch.float32\n                ).mean().cpu() * 100\n                tmp.append((loss.item(), accuracy.item()))\n        losses_val.append(\n            (\n                np.mean(tmp, axis=0),\n                np.percentile(tmp, 25, axis=0),\n                np.percentile(tmp, 75, axis=0),\n            )\n        )\n        # New: \u0417\u0430\u043f\u0438\u0441\u044c \u0432 tensorboard.\n        with test_summary_writer as writer:\n            writer.add_scalar(\"loss\", losses_val[-1][0][0], global_step=pbar.n)\n            writer.add_scalar(\"accuracy\", losses_val[-1][0][1], global_step=pbar.n)\n\n        # New: \u0421\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u0435 \u0447\u0435\u043a\u043f\u043e\u0438\u043d\u0442\u0430.\n        acc = losses_val[-1][0][1]\n        if acc > best_acc:\n            best_acc = acc\n            torch.save(model.state_dict(), checkpoint_path)\n\n        # \u041e\u0431\u043d\u043e\u0432\u043b\u0435\u043d\u0438\u0435 \u0433\u0440\u0430\u0444\u0438\u043a\u043e\u0432.\n        if (epoch + 1) % REDRAW_EVERY != 0:\n            continue\n        clear_output(wait=False)\n        # New:\n        print(\n            \"\u042d\u043f\u043e\u0445\u0430: %s\\n\"\n            \"\u041b\u0443\u0447\u0448\u0430\u044f \u0434\u043e\u043b\u044f \u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u044b\u0445 \u043e\u0442\u0432\u0435\u0442\u043e\u0432: %s\\n\"\n            \"\u0422\u0435\u043a\u0443\u0449\u0430\u044f \u0434\u043e\u043b\u044f \u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u044b\u0445 \u043e\u0442\u0432\u0435\u0442\u043e\u0432: %s\" % (epoch + 1, best_acc, acc)\n        )\n        passed += pbar.format_dict[\"elapsed\"]\n        pbar = tqdm(total=EPOCHS * steps_per_epoch, miniters=5)\n        pbar.update((epoch + 1) * steps_per_epoch)\n        x_vals = np.arange(epoch + 1)\n        _, ax = plt.subplots(1, 2, figsize=(15, 5))\n        stats = np.array(losses)\n        stats_val = np.array(losses_val)\n        ax[1].set_ylim(stats_val[:, 0, 1].min() - 5, 100)\n        ax[1].grid(axis=\"y\")\n        for i, title in enumerate([\"CCE\", \"Accuracy\"]):\n            ax[i].plot(x_vals, stats[:, 0, i], label=\"train\")\n            ax[i].fill_between(x_vals, stats[:, 1, i], stats[:, 2, i], alpha=0.4)\n            ax[i].plot(x_vals, stats_val[:, 0, i], label=\"val\")\n            ax[i].fill_between(\n                x_vals, stats_val[:, 1, i], stats_val[:, 2, i], alpha=0.4\n            )\n            ax[i].legend()\n            ax[i].set_title(title)\n        plt.show()\n\n    # New:\n    model.load_state_dict(torch.load(checkpoint_path))\n    print(\"\u041e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u0437\u0430\u043a\u043e\u043d\u0447\u0435\u043d\u043e \u0437\u0430 %s \u0441\u0435\u043a\u0443\u043d\u0434\" % passed)\n\n    return dataloader"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5b0b3947",
            "metadata": {
                "trusted": false
            },
            "outputs": [],
            "source": "# \u0417\u0430\u043f\u0443\u0441\u043a tensorboard \u0432 Jupyter Notebook.\n%tensorboard --logdir runs/tensorboard"
        },
        {
            "cell_type": "markdown",
            "id": "a0ba50f5",
            "metadata": {},
            "source": "### \u0412\u044b\u0431\u043e\u0440 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u043f\u043e\u0442\u0435\u0440\u044c \u0438 \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0442\u043e\u0440\u0430 \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u043d\u043e\u0433\u043e \u0441\u043f\u0443\u0441\u043a\u0430"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "26fbf7c9",
            "metadata": {
                "trusted": false
            },
            "outputs": [],
            "source": "# New: weight_decay, label_smoothing, scheduler_step_size.\ndef train_classifier(\n    model: nn.Module,\n    learning_rate=5e-3,\n    batch_size=128,\n    epochs=EPOCHS,\n    momentum=0.9,\n    # \u0420\u0435\u0433\u0443\u043b\u044f\u0440\u0438\u0437\u0430\u0446\u0438\u044f \u043c\u043e\u0434\u0435\u043b\u0438 \u0437\u0430 \u0441\u0447\u0451\u0442 \u043a\u043e\u044d\u0444\u0444\u0438\u0446\u0438\u0435\u043d\u0442\u0430, \u0443\u0447\u0438\u0442\u044b\u0432\u0430\u044e\u0449\u0435\u0433\u043e \u0441\u043b\u043e\u0436\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438.\n    # \u041d\u043e\u0440\u043c\u0430 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u0431\u0443\u0434\u0435\u0442 \u043f\u0440\u0438\u0431\u0430\u0432\u043b\u0435\u043d\u0430 \u043a \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u043f\u043e\u0442\u0435\u0440\u044c. \u0427\u0435\u043c \u0431\u043e\u043b\u044c\u0448\u0435\n    # weight_decay, \u0442\u0435\u043c \u0441\u0438\u043b\u044c\u043d\u0435\u0435 \u0448\u0442\u0440\u0430\u0444 \u0437\u0430 \u0441\u043b\u043e\u0436\u043d\u043e\u0441\u0442\u044c.\n    weight_decay=1e-5,\n    # \u0414\u043e\u0431\u0430\u0432\u043b\u044f\u0435\u043c \u0441\u0433\u043b\u0430\u0436\u0438\u0432\u0430\u043d\u0438\u0435 \u0446\u0435\u043b\u0435\u0432\u044b\u0445 \u043c\u0435\u0442\u043e\u043a, \u044d\u0442\u043e \u0443\u0432\u0435\u043b\u0438\u0447\u0438\u0442 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u043f\u043e\u0442\u0435\u0440\u044c\n    #   \u043d\u043e \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u0430\u044f \u043c\u043e\u0434\u0435\u043b\u044c \u0431\u0443\u0434\u0435\u0442 \u0431\u043e\u043b\u0435\u0435 \u0443\u0441\u0442\u043e\u0439\u0447\u0438\u0432\u043e\u0439 \u043a \u0432\u044b\u0431\u0440\u043e\u0441\u0430\u043c \u0432 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0435\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435.\n    label_smoothing=0.1,\n    # \u041f\u043e\u0441\u0442\u0435\u043f\u0435\u043d\u043d\u043e\u0435 \u0443\u043c\u0435\u043d\u044c\u0448\u0435\u043d\u0438\u0435 \u0448\u0430\u0433\u0430 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043a\u0430\u0436\u0434\u044b\u0435 N \u044d\u043f\u043e\u0445.\n    scheduler_step_size=240,\n):\n    # New: label_smoothing\n    criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n    # New: weight_decay\n    optimizer = optim.SGD(\n        model.parameters(),\n        lr=learning_rate,\n        momentum=momentum,\n        weight_decay=weight_decay,\n    )\n    dataloader = create_dataloader(batch_size=batch_size)\n    # New: scheduler.\n    # \u0414\u043e\u0431\u0430\u0432\u043b\u044f\u0435\u043c \u043f\u043e\u0441\u0442\u0435\u043f\u0435\u043d\u043d\u043e\u0435 \u0443\u043c\u0435\u043d\u044c\u0448\u0435\u043d\u0438\u0435 \u0448\u0430\u0433\u0430 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043a\u0430\u0436\u0434\u044b\u0435 step_size\n    #   \u044d\u043f\u043e\u0445.\n    scheduler = optim.lr_scheduler.StepLR(\n        optimizer=optimizer, step_size=scheduler_step_size, gamma=0.5\n    )\n\n    return train(\n        model,\n        criterion=criterion,\n        optimizer=optimizer,\n        dataloader=dataloader,\n        epochs=epochs,\n        scheduler=scheduler,\n    )\n\n\ndataloader = train_classifier(model)"
        },
        {
            "cell_type": "markdown",
            "id": "6fee84cb",
            "metadata": {},
            "source": "### \u041f\u0440\u043e\u0432\u0435\u0440\u043a\u0430 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u043e \u043a\u043b\u0430\u0441\u0441\u0430\u043c \u043d\u0430 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0435\u0439 \u0438 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0430\u0445"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f207d448",
            "metadata": {
                "trusted": false
            },
            "outputs": [],
            "source": "def report_classification_results(dataloader: DataLoader):\n    y_pred = []\n    y_true = []\n    with torch.no_grad():  # \u043e\u0442\u043a\u043b\u044e\u0447\u0435\u043d\u0438\u0435 \u0430\u0432\u0442\u043e\u043c\u0430\u0442\u0438\u0447\u0435\u0441\u043a\u043e\u0433\u043e \u0434\u0438\u0444\u0444\u0435\u0440\u0435\u043d\u0446\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f\n        for _, data in enumerate(dataloader, 0):\n            inputs, labels = data\n            # \u043d\u0430 GPU\n            # inputs, labels = inputs.to(device), labels.to(device)\n\n            outputs = model(inputs).detach().cpu().numpy()\n            y_pred.append(outputs)\n            y_true.append(labels.numpy())\n        y_true = np.concatenate(y_true)\n        y_pred = np.concatenate(y_pred)\n        print(\n            classification_report(\n                y_true.argmax(axis=-1),\n                y_pred.argmax(axis=-1),\n                digits=4,\n                target_names=list(map(str, CLASSES)),\n            )\n        )"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d0619cfd",
            "metadata": {
                "trusted": false
            },
            "outputs": [],
            "source": "def compare_classification_reports(dataloader: dict[str, DataLoader]):\n    for part in [\"train\", \"test\"]:\n        print(part)\n        report_classification_results(dataloader[part])\n        part != \"test\" and print(\"-\" * 53)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fea34b3c",
            "metadata": {
                "trusted": false
            },
            "outputs": [],
            "source": "compare_classification_reports(dataloader)"
        },
        {
            "cell_type": "markdown",
            "id": "66a76261",
            "metadata": {},
            "source": "### \u0410\u043d\u0430\u043b\u0438\u0437 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u043e\u0432 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043c\u043e\u0434\u0435\u043b\u0438\n\u0412 \u043f\u0440\u0435\u0434\u044b\u0434\u0443\u0449\u0435\u0439 \u043c\u043e\u0434\u0435\u043b\u0438 (\u0441 MaxPulling) \u0431\u044b\u043b\u0430 \u0434\u043e\u0432\u043e\u043b\u044c\u043d\u043e \u0432\u044b\u0441\u043e\u043a\u0430\u044f \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u0438 \u0441\u043a\u043e\u0440\u043e\u0441\u0442\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f,\n\u043e\u0434\u043d\u0430\u043a\u043e \u043c\u043e\u0434\u0435\u043b\u044c \u0431\u044b\u043b\u0430 \u0441\u043a\u043b\u043e\u043d\u043d\u0430 \u043a \u043f\u0435\u0440\u0435\u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044e.\n\n\u0420\u0435\u0433\u0443\u043b\u044f\u0440\u0438\u0437\u0430\u0446\u0438\u044f \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439, dropout, label smoothing\n\u0438 weight decay \u0434\u0430\u043b\u0438 \u0441\u0432\u043e\u0438 \u043f\u043b\u043e\u0434\u044b: \u043f\u0435\u0440\u0435\u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u0443\u0448\u043b\u043e, \u043f\u0440\u0438 \u044d\u0442\u043e\u043c \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438\n\u0443\u043b\u0443\u0447\u0448\u0438\u043b\u0430\u0441\u044c \u043d\u0430 2% \u043f\u043e \u0441\u0440\u0430\u0432\u043d\u0435\u043d\u0438\u044e \u0441 \u043b\u0443\u0447\u0448\u0435\u0439 \u0432\u0435\u0440\u0441\u0438\u0435\u0439 \u043c\u043e\u0434\u0435\u043b\u0438\n\u0432\u0442\u043e\u0440\u043e\u0439 \u043b\u0430\u0431\u043e\u0440\u0430\u0442\u043e\u0440\u043d\u043e\u0439 \u0440\u0430\u0431\u043e\u0442\u044b.\n\n\u041a \u0441\u043e\u0436\u0430\u043b\u0435\u043d\u0438\u044e, \u0432\u0437\u0430\u043c\u0435\u043d \u0434\u043b\u0438\u0442\u0435\u043b\u044c\u043d\u043e\u0441\u0442\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u0432\u043e\u0437\u0440\u043e\u0441\u043b\u0430 \u0432 5 \u0440\u0430\u0437."
        },
        {
            "cell_type": "markdown",
            "id": "4df09b93",
            "metadata": {},
            "source": "\u041d\u0430 \u043b\u0438\u0446\u043e \u0442\u0430\u043a \u0436\u0435 \u043f\u0435\u0440\u0435\u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435: \u0432 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0435\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435 \u0445\u0430\u0440\u0430\u043a\u0442\u0435\u0440\u0438\u0441\u0442\u0438\u043a\u0438 \u0431\u044b\u043b\u0438 \u043f\u043e\u0447\u0442\u0438 \u0438\u0434\u0435\u0430\u043b\u044c\u043d\u044b\u043c\u0438,\n\u0430 \u0432 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u0434\u043b\u044f \u043d\u0435\u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u043a\u043b\u0430\u0441\u0441\u043e\u0432 \u0441\u0440\u0435\u0434\u043d\u0438\u043c\u0438. \u0421\u043a\u043e\u0440\u0440\u0435\u043a\u0442\u0438\u0440\u0443\u0435\u043c \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u0434\u043b\u044f \u0443\u0441\u0442\u0440\u0430\u043d\u0435\u043d\u0438\u044f\n\u044d\u0442\u043e\u0433\u043e \u0444\u0435\u043d\u043e\u043c\u0435\u043d\u0430 \u0432 \u043d\u0430\u0434\u0435\u0436\u0434\u0435 \u0443\u043b\u0443\u0447\u0448\u0438\u0442\u044c \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u043e \u043c\u043e\u0434\u0435\u043b\u0438."
        },
        {
            "cell_type": "markdown",
            "id": "73f30fe1",
            "metadata": {},
            "source": "\u041f\u043e\u0434\u0431\u0435\u0440\u0451\u043c \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u044d\u043f\u043e\u0445."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fd1da242",
            "metadata": {
                "trusted": false
            },
            "outputs": [],
            "source": "model = Cifar100_CNN(hidden_size=HIDDEN_SIZE, classes=len(CLASSES))\ndataloader = train_classifier(model, epochs=30)\ncompare_classification_reports(dataloader)"
        },
        {
            "cell_type": "markdown",
            "id": "f2ac89fa",
            "metadata": {},
            "source": "## \u042d\u043a\u0441\u043f\u043e\u0440\u0442 \u043c\u043e\u0434\u0435\u043b\u0438"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1b5d5fba",
            "metadata": {
                "trusted": false
            },
            "outputs": [],
            "source": "model_path = Path(\"models\")\nmodel_filename = \"cifar100_cnn_augmented.pt\"\n\nmodel_path.mkdir(exist_ok=True)\n\nmodel_file_path = model_path / model_filename\n\ntorch.save(model, model_file_path)\n# \u0437\u0430\u0433\u0440\u0443\u0437\u043a\u0430\nnew_model_2 = torch.load(model_file_path)\nnew_model_2.eval()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1763231f",
            "metadata": {
                "trusted": false
            },
            "outputs": [],
            "source": "# \u0432\u0445\u043e\u0434\u043d\u043e\u0439 \u0442\u0435\u043d\u0437\u043e\u0440 \u0434\u043b\u044f \u043c\u043e\u0434\u0435\u043b\u0438\nonnx_model_filename = \"cifar100_cnn_augmented.onnx\"\nx = torch.randn(1, 32, 32, 3, requires_grad=True).to(device)\ntorch_out = model(x)\n\n# \u044d\u043a\u0441\u043f\u043e\u0440\u0442 \u043c\u043e\u0434\u0435\u043b\u0438\ntorch.onnx.export(\n    model,  # \u043c\u043e\u0434\u0435\u043b\u044c\n    x,  # \u0432\u0445\u043e\u0434\u043d\u043e\u0439 \u0442\u0435\u043d\u0437\u043e\u0440 (\u0438\u043b\u0438 \u043a\u043e\u0440\u0442\u0435\u0436 \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u0438\u0445 \u0442\u0435\u043d\u0437\u043e\u0440\u043e\u0432)\n    model_path\n    / onnx_model_filename,  # \u043a\u0443\u0434\u0430 \u0441\u043e\u0445\u0440\u0430\u043d\u0438\u0442\u044c (\u043b\u0438\u0431\u043e \u043f\u0443\u0442\u044c \u043a \u0444\u0430\u0439\u043b\u0443 \u043b\u0438\u0431\u043e fileObject)\n    export_params=True,  # \u0441\u043e\u0445\u0440\u0430\u043d\u044f\u0435\u0442 \u0432\u0435\u0441\u0430 \u043e\u0431\u0443\u0447\u0435\u043d\u043d\u044b\u0445 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u0432\u043d\u0443\u0442\u0440\u0438 \u0444\u0430\u0439\u043b\u0430 \u043c\u043e\u0434\u0435\u043b\u0438\n    opset_version=9,  # \u0432\u0435\u0440\u0441\u0438\u044f ONNX\n    do_constant_folding=True,  # \u0441\u043b\u0435\u0434\u0443\u0435\u0442 \u043b\u0438 \u0432\u044b\u043f\u043e\u043b\u043d\u044f\u0442\u044c \u0443\u043a\u043e\u0440\u0430\u0447\u0438\u0432\u0430\u043d\u0438\u0435 \u043a\u043e\u043d\u0441\u0442\u0430\u043d\u0442 \u0434\u043b\u044f \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0446\u0438\u0438\n    input_names=[\"input\"],  # \u0438\u043c\u044f \u0432\u0445\u043e\u0434\u043d\u043e\u0433\u043e \u0441\u043b\u043e\u044f\n    output_names=[\"output\"],  # \u0438\u043c\u044f \u0432\u044b\u0445\u043e\u0434\u043d\u043e\u0433\u043e \u0441\u043b\u043e\u044f\n    dynamic_axes={\n        \"input\": {\n            0: \"batch_size\"\n        },  # \u0434\u0438\u043d\u0430\u043c\u0438\u0447\u043d\u044b\u0435 \u043e\u0441\u0438, \u0432 \u0434\u0430\u043d\u043d\u043e\u043c \u0441\u043b\u0443\u0447\u0430\u0435 \u0442\u043e\u043b\u044c\u043a\u043e \u0440\u0430\u0437\u043c\u0435\u0440 \u043f\u0430\u043a\u0435\u0442\u0430\n        \"output\": {0: \"batch_size\"},\n    },\n)"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}